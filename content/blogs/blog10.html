

<div id="climate-change-and-temperature-anomalies" class="section level1">
<h1>Climate change and temperature anomalies</h1>
<pre class="r"><code># Loading the file

weather &lt;- 
  read_csv(&quot;https://data.giss.nasa.gov/gistemp/tabledata_v3/NH.Ts+dSST.csv&quot;, 
           skip = 1, 
           na = &quot;***&quot;)</code></pre>
<pre class="r"><code># Selecting the relevant variables

weather_select &lt;- weather %&gt;%
  select(-c(14, 15, 16, 17, 18, 19))

# Adjusting the selected dataframe

tidyweather &lt;- weather_select %&gt;%
  pivot_longer(cols = 2:13, names_to = &quot;month&quot;, values_to = &quot;delta&quot;)
glimpse(tidyweather)</code></pre>
<pre><code>## Rows: 1,680
## Columns: 3
## $ Year  &lt;dbl&gt; 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1...
## $ month &lt;chr&gt; &quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;...
## $ delta &lt;dbl&gt; -0.54, -0.38, -0.26, -0.37, -0.11, -0.22, -0.23, -0.24, -0.26...</code></pre>
<div id="plotting-information" class="section level2">
<h2>Plotting Information</h2>
<pre class="r"><code>#Preparing the dataset for plotting

tidyweather_new &lt;- tidyweather %&gt;%
  mutate(date = ymd(paste(as.character(Year), month, &quot;1&quot;)),
         month = month(date, label=TRUE),
         year = year(date))

# Plotting the data

 p1 &lt;- ggplot(tidyweather_new, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color=&quot;red&quot;) +
  theme_clean() +
  labs (
    title = &quot;Weather Anomalies&quot;
  )

p1</code></pre>
<p><img src="blog10_files/figure-html/scatter_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Applying a facet wrap to the plot

p2 &lt;- p1 + facet_wrap(~month)

p2</code></pre>
<p><img src="blog10_files/figure-html/facet_wrap-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Filtering the dataset

comparison &lt;- tidyweather %&gt;% 
  filter(Year&gt;= 1881) %&gt;%     #remove years prior to 1881

# Creating an &quot;interval&quot; variable
  
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ &quot;1881-1920&quot;,
    Year %in% c(1921:1950) ~ &quot;1921-1950&quot;,
    Year %in% c(1951:1980) ~ &quot;1951-1980&quot;,
    Year %in% c(1981:2010) ~ &quot;1981-2010&quot;,
    TRUE ~ &quot;2011-present&quot;
  ))</code></pre>
<pre class="r"><code># Creating a density plot

ggplot(comparison, aes(x=delta, fill=interval))+
  geom_density(alpha=0.2) +   
  theme_bw() +              
  labs (
    title = &quot;Density Plot for Monthly Temperature Anomalies&quot;,
    y     = &quot;Density&quot;     
  )</code></pre>
<p><img src="blog10_files/figure-html/density_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Creating yearly averages

average_annual_anomaly &lt;- tidyweather %&gt;% 
  group_by(Year) %&gt;%   #grouping data by Year
  
# Finding the mean delta
  
  summarise(annual_average_delta = mean(delta, na.rm=TRUE)) 

average_annual_anomaly</code></pre>
<pre><code>## # A tibble: 140 x 2
##     Year annual_average_delta
##    &lt;dbl&gt;                &lt;dbl&gt;
##  1  1880               -0.315
##  2  1881               -0.19 
##  3  1882               -0.214
##  4  1883               -0.318
##  5  1884               -0.439
##  6  1885               -0.405
##  7  1886               -0.415
##  8  1887               -0.403
##  9  1888               -0.222
## 10  1889               -0.161
## # ... with 130 more rows</code></pre>
<pre class="r"><code># Plotting the data

ggplot(average_annual_anomaly, aes(x=Year, y= annual_average_delta))+
  geom_point()+
  geom_smooth(method = &quot;loess&quot;) +
  theme_bw() +
  labs (
    title = &quot;Average Yearly Anomaly&quot;,
    y     = &quot;Average Annual Delta&quot;
  )                         </code></pre>
<p><img src="blog10_files/figure-html/averaging1-1.png" width="648" style="display: block; margin: auto;" />
## Confidence Interval for <code>delta</code></p>
<pre class="r"><code>#Finding the confidence interval using a formula

library(infer)
formula_ci &lt;- comparison %&gt;%
  filter(interval == &quot;2011-present&quot;) %&gt;%
  summarize(mean_dev=mean(delta, na.rm=TRUE), sd_dev=sd(delta, na.rm=TRUE), count = n(), se_dev=sd_dev/sqrt(count), t_critical = qt(0.975, count-1), margin_of_error = t_critical * se_dev, temp_low = mean_dev - margin_of_error, temp_high = mean_dev + margin_of_error)

formula_ci</code></pre>
<pre><code>## # A tibble: 1 x 8
##   mean_dev sd_dev count se_dev t_critical margin_of_error temp_low temp_high
##      &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1    0.966  0.262   108 0.0252       1.98          0.0501    0.916      1.02</code></pre>
<pre class="r"><code># Finding the confidence interval using bootstrap

boot_temp &lt;- comparison %&gt;%
  filter(interval == &quot;2011-present&quot;) %&gt;%
  specify(response = delta) %&gt;%
  generate (reps = 100000, type = &quot;bootstrap&quot;) %&gt;%
  calculate (stat = &quot;mean&quot;)

  percentile_ci &lt;- boot_temp %&gt;%
    get_confidence_interval(level = 0.975, type = &quot;percentile&quot;)
percentile_ci</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1    0.910     1.02</code></pre>
</div>
<div id="comment" class="section level2">
<h2>Comment</h2>
<p>We have found a confidence interval using two methods. The results show us that since 2011 the average change in global temperature has been 0.97, just under the 1 degree threshold. However, based on the standard error of this dataset we can be 95% certain that the population’s mean lies within a range that includes values as high as 1.03 degrees of global temperature change.</p>
</div>
</div>
<div id="general-social-survey-gss" class="section level1">
<h1>General Social Survey (GSS)</h1>
<pre class="r"><code>gss &lt;- read_csv(here::here(&quot;data&quot;, &quot;smallgss2016.csv&quot;), 
                na = c(&quot;&quot;, &quot;Don&#39;t know&quot;,
                       &quot;No answer&quot;, &quot;Not applicable&quot;))

glimpse(gss)</code></pre>
<pre><code>## Rows: 2,867
## Columns: 7
## $ emailmin &lt;chr&gt; &quot;0&quot;, &quot;30&quot;, &quot;NA&quot;, &quot;10&quot;, &quot;NA&quot;, &quot;0&quot;, &quot;0&quot;, &quot;NA&quot;, &quot;0&quot;, &quot;NA&quot;, &quot;0...
## $ emailhr  &lt;chr&gt; &quot;12&quot;, &quot;0&quot;, &quot;NA&quot;, &quot;0&quot;, &quot;NA&quot;, &quot;2&quot;, &quot;40&quot;, &quot;NA&quot;, &quot;0&quot;, &quot;NA&quot;, &quot;2...
## $ snapchat &lt;chr&gt; &quot;NA&quot;, &quot;No&quot;, &quot;No&quot;, &quot;NA&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;NA&quot;, &quot;Yes&quot;, &quot;NA&quot;, &quot;N...
## $ instagrm &lt;chr&gt; &quot;NA&quot;, &quot;No&quot;, &quot;No&quot;, &quot;NA&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;NA&quot;, &quot;Yes&quot;, &quot;NA&quot;, &quot;...
## $ twitter  &lt;chr&gt; &quot;NA&quot;, &quot;No&quot;, &quot;No&quot;, &quot;NA&quot;, &quot;No&quot;, &quot;No&quot;, &quot;NA&quot;, &quot;No&quot;, &quot;NA&quot;, &quot;No&quot;...
## $ sex      &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Mal...
## $ degree   &lt;chr&gt; &quot;Bachelor&quot;, &quot;High school&quot;, &quot;Bachelor&quot;, &quot;High school&quot;, &quot;Gra...</code></pre>
<pre class="r"><code>skim(gss)</code></pre>
<table>
<caption>(#tab:read_gss_data)Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">gss</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">2867</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">7</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">7</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">emailmin</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">15</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">emailhr</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">42</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">snapchat</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">instagrm</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">twitter</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">sex</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">degree</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">14</td>
<td align="right">0</td>
<td align="right">6</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<div id="instagram-and-snapchat-by-sex" class="section level2">
<h2>Instagram and Snapchat, by sex</h2>
<pre class="r"><code>#Creating new variables
social_usage &lt;- gss %&gt;%
  mutate(snap_insta = case_when(snapchat == &quot;Yes&quot; &amp; instagrm == &quot;Yes&quot; ~ &quot;Yes&quot;, snapchat == &quot;Yes&quot; | instagrm == &quot;Yes&quot; ~ &quot;Yes&quot;, snapchat == &quot;No&quot; &amp; instagrm == &quot;No&quot; ~ &quot;No&quot;, snapchat == &quot;NA&quot; &amp; instagrm == &quot;NA&quot; ~ &quot;NA&quot; ))

#Calculating the proportions of Yes&#39;s and those who answered
share_yes &lt;- social_usage %&gt;% 
  count(snap_insta == &quot;Yes&quot;) %&gt;% 
  mutate(n/sum(n)*100)

share_yes_no &lt;- social_usage %&gt;%
  filter(snap_insta != &quot;NA&quot;)

share_yes_no %&gt;% 
  count(snap_insta == &quot;Yes&quot;) %&gt;% 
  mutate(n/sum(n)*100)</code></pre>
<pre><code>## # A tibble: 2 x 3
##   `snap_insta == &quot;Yes&quot;`     n `n/sum(n) * 100`
##   &lt;lgl&gt;                 &lt;int&gt;            &lt;dbl&gt;
## 1 FALSE                   858             62.5
## 2 TRUE                    514             37.5</code></pre>
<pre class="r"><code>#Social media usage
social_stats &lt;- social_usage %&gt;%
  group_by(snap_insta) %&gt;%
  count(snap_insta) %&gt;%
  pivot_wider(names_from = snap_insta, values_from = n) %&gt;%
  mutate(proporation_yes = Yes/(Yes+No))

social_stats</code></pre>
<pre><code>## # A tibble: 1 x 4
##    `NA`    No   Yes proporation_yes
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;           &lt;dbl&gt;
## 1  1495   858   514           0.375</code></pre>
<pre class="r"><code>#95% confidence interval
ci_share &lt;- social_usage %&gt;%
  group_by(sex, snap_insta) %&gt;%
  count(snap_insta) %&gt;%
  pivot_wider(names_from = snap_insta, values_from = n) %&gt;%
  mutate(mean = Yes/(Yes+No), se = sqrt(mean*(1-mean)/(Yes+No)), t_critical = qt(0.975, (Yes+No)-1), lower = mean - t_critical*se, upper = mean + t_critical*se)

ci_share</code></pre>
<pre><code>## # A tibble: 2 x 9
## # Groups:   sex [2]
##   sex     `NA`    No   Yes  mean     se t_critical lower upper
##   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 Female   822   447   322 0.419 0.0178       1.96 0.384 0.454
## 2 Male     673   411   192 0.318 0.0190       1.96 0.281 0.356</code></pre>
<pre class="r"><code>#Absolute number of men and women using social media
ci_gender &lt;- social_usage %&gt;%
  group_by(sex, snap_insta) %&gt;%
  count(snap_insta)

ci_gender1 &lt;- social_usage %&gt;%
  group_by(sex, snap_insta) %&gt;%
  count(snap_insta) %&gt;%
  pivot_wider(names_from = snap_insta, values_from = n)

ci_gender1</code></pre>
<pre><code>## # A tibble: 2 x 4
## # Groups:   sex [2]
##   sex     `NA`    No   Yes
##   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;
## 1 Female   822   447   322
## 2 Male     673   411   192</code></pre>
</div>
<div id="twitter-by-education-level" class="section level2">
<h2>Twitter, by education level</h2>
<pre class="r"><code>#Turning to Factor variable and non alphabetical
twitter_users &lt;- gss %&gt;%
  group_by(degree) %&gt;%
  count(twitter)

level_order &lt;- c(&quot;Lt high school&quot;, &quot;High school&quot;, &quot;Junior college&quot;, &quot;Bachelor&quot;, &quot;Graduate&quot;)

twitter_count &lt;- gss %&gt;% 
  group_by(degree) %&gt;%
  mutate(degree = factor(degree, levels = level_order))

#Creating new variable bachelor_graduate
twitter_edu &lt;- twitter_count %&gt;%
  mutate(bachelor_graduate = case_when(degree == &quot;Bachelor&quot; | degree == &quot;Graduate&quot; ~ &quot;Yes&quot;, degree == &quot;High school&quot; | degree == &quot;Junior college&quot; | degree == &quot;Lt high school&quot; ~ &quot;No&quot;, degree == &quot;NA&quot; ~ &quot;NA&quot; ))

#Proportion of bachelor_graduate
twitter_data &lt;- twitter_edu %&gt;%
  group_by(bachelor_graduate, twitter) %&gt;%
  count(bachelor_graduate, twitter) %&gt;%
  filter(bachelor_graduate == &quot;Yes&quot;) %&gt;%
  pivot_wider(names_from = twitter, values_from = n) %&gt;%
  mutate(twitter_yes = Yes/(Yes+No))

twitter_data_set &lt;- twitter_edu %&gt;%
  group_by(bachelor_graduate, twitter) %&gt;%
  filter(bachelor_graduate == &quot;Yes&quot;, twitter != &quot;NA&quot;) %&gt;%
  summarise(count = n()) %&gt;% 
  mutate(per_tw = count/sum(count))

twitter_data_set</code></pre>
<pre><code>## # A tibble: 2 x 4
## # Groups:   bachelor_graduate [1]
##   bachelor_graduate twitter count per_tw
##   &lt;chr&gt;             &lt;chr&gt;   &lt;int&gt;  &lt;dbl&gt;
## 1 Yes               No        375  0.767
## 2 Yes               Yes       114  0.233</code></pre>
<pre class="r"><code>#Confidence intervals with 95% of Yes and No, and summary
twitter_CI_yes &lt;- twitter_edu %&gt;%
  group_by(bachelor_graduate, twitter) %&gt;%
  count(bachelor_graduate, twitter) %&gt;%
  pivot_wider(names_from = twitter, values_from = n) %&gt;%
  mutate(mean = Yes/(Yes+No), se = sqrt(mean*(1-mean)/(Yes+No)), t_critical = qt(0.975, (Yes+No)-1), lower = mean - t_critical*se, upper = mean + t_critical*se)

twitter_CI_no &lt;- twitter_edu %&gt;%
  group_by(bachelor_graduate, twitter) %&gt;%
  count(bachelor_graduate, twitter) %&gt;%
  pivot_wider(names_from = twitter, values_from = n) %&gt;%
  mutate(mean = No/(Yes+No), se = sqrt(mean*(1-mean)/(Yes+No)), t_critical = qt(0.975, (Yes+No)-1), lower = mean - t_critical*se, upper = mean + t_critical*se)

twitter_CI_yes</code></pre>
<pre><code>## # A tibble: 3 x 9
## # Groups:   bachelor_graduate [3]
##   bachelor_graduate  `NA`    No   Yes   mean      se t_critical  lower  upper
##   &lt;chr&gt;             &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 No                 1123   741   141  0.160  0.0123       1.96  0.136  0.184
## 2 Yes                 365   375   114  0.233  0.0191       1.96  0.196  0.271
## 3 &lt;NA&gt;                  7     1    NA NA     NA           NA    NA     NA</code></pre>
<pre class="r"><code>twitter_CI_no</code></pre>
<pre><code>## # A tibble: 3 x 9
## # Groups:   bachelor_graduate [3]
##   bachelor_graduate  `NA`    No   Yes   mean      se t_critical  lower  upper
##   &lt;chr&gt;             &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 No                 1123   741   141  0.840  0.0123       1.96  0.816  0.864
## 2 Yes                 365   375   114  0.767  0.0191       1.96  0.729  0.804
## 3 &lt;NA&gt;                  7     1    NA NA     NA           NA    NA     NA</code></pre>
<pre class="r"><code>twitter_CI_summary &lt;- twitter_data_set %&gt;%
  summarise(count, per_tw, se = sqrt((per_tw*(1-per_tw)/sum(count))), t_critical = qt(0.975, count-1), margin_of_error = t_critical * se, lower = per_tw - margin_of_error, higher = per_tw + margin_of_error) 

twitter_CI_summary</code></pre>
<pre><code>## # A tibble: 2 x 8
## # Groups:   bachelor_graduate [1]
##   bachelor_graduate count per_tw     se t_critical margin_of_error lower higher
##   &lt;chr&gt;             &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1 Yes                 375  0.767 0.0191       1.97          0.0376 0.729  0.804
## 2 Yes                 114  0.233 0.0191       1.98          0.0379 0.195  0.271</code></pre>
<p>The confidence intervals do not overlap as the lower bound of “No” is higher than the upper bound of “Yes”.</p>
</div>
<div id="email-usage" class="section level2">
<h2>Email usage</h2>
<pre class="r"><code>#Creating new variable
email_usage &lt;- gss

email_usage[email_usage == &quot;NA&quot;] &lt;- NA

email_visualize &lt;- email_usage %&gt;% 
  na.omit() %&gt;% 
  mutate(emailmin = as.integer(emailmin),
         emailhr = as.integer(emailhr),
         email = emailmin + emailhr*60)

#Visualizing the distribution of new variable
ggplot(data = email_visualize, aes(x = email)) + geom_boxplot() + labs(title = &quot;Distribution on time spent on email weekly&quot;, x = &quot;Minutes per week&quot;, y = &quot;&quot;) + theme_clean() + NULL</code></pre>
<p><img src="blog10_files/figure-html/email-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(data = email_visualize, aes(x = email)) + geom_histogram() + labs(title = &quot;Distribution on time spent on email weekly&quot;, x = &quot;Minutes per week&quot;, y = &quot;Number of people&quot;) + theme_clean() + NULL</code></pre>
<p><img src="blog10_files/figure-html/email-2.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#95% CI bootstrap for mean time Americans spend on email weekly
library(infer)

email_95 &lt;- email_visualize %&gt;%
  specify(response = email) %&gt;%
  generate (reps = 1000, type = &quot;bootstrap&quot;) %&gt;%
  calculate (stat = &quot;mean&quot;)

email_95_ci &lt;- email_95 %&gt;%
    get_confidence_interval(level = 0.95, type = &quot;percentile&quot;)

email_95_ci %&gt;%
  mutate(lower_ci = lower_ci/60, upper_ci = upper_ci/60)</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1     6.57     8.24</code></pre>
<pre class="r"><code>#99% CI bootstrap for mean time Americans spend on email weekly
email_99 &lt;- email_visualize %&gt;%
  specify(response = email) %&gt;%
  generate (reps = 1000, type = &quot;bootstrap&quot;) %&gt;%
  calculate (stat = &quot;mean&quot;)

email_99_ci &lt;- email_99 %&gt;%
    get_confidence_interval(level = 0.99, type = &quot;percentile&quot;)

email_99_ci</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1     381.     515.</code></pre>
<p>Considering several outliers it is better to use the median number as a measure of the typical amount American spend on their email weekly. The mean would be skewed to the right.</p>
<p>A 99% interval would be wider than the 95% one because it includes more variables of the sample.</p>
</div>
</div>
<div id="trumps-approval-margins" class="section level1">
<h1>Trump’s Approval Margins</h1>
<pre class="r"><code># Import approval polls data
approval_polllist &lt;- read_csv(here::here(&#39;data&#39;, &#39;approval_polllist.csv&#39;))

glimpse(approval_polllist)</code></pre>
<pre><code>## Rows: 15,619
## Columns: 22
## $ president           &lt;chr&gt; &quot;Donald Trump&quot;, &quot;Donald Trump&quot;, &quot;Donald Trump&quot;,...
## $ subgroup            &lt;chr&gt; &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;, &quot;All pol...
## $ modeldate           &lt;chr&gt; &quot;9/27/2020&quot;, &quot;9/27/2020&quot;, &quot;9/27/2020&quot;, &quot;9/27/20...
## $ startdate           &lt;chr&gt; &quot;1/20/2017&quot;, &quot;1/20/2017&quot;, &quot;1/20/2017&quot;, &quot;1/21/20...
## $ enddate             &lt;chr&gt; &quot;1/22/2017&quot;, &quot;1/22/2017&quot;, &quot;1/24/2017&quot;, &quot;1/23/20...
## $ pollster            &lt;chr&gt; &quot;Gallup&quot;, &quot;Morning Consult&quot;, &quot;Ipsos&quot;, &quot;Gallup&quot;,...
## $ grade               &lt;chr&gt; &quot;B&quot;, &quot;B/C&quot;, &quot;B-&quot;, &quot;B&quot;, &quot;B-&quot;, &quot;C+&quot;, &quot;B+&quot;, &quot;B&quot;, &quot;...
## $ samplesize          &lt;dbl&gt; 1500, 1992, 1632, 1500, 1651, 1500, 1190, 1500,...
## $ population          &lt;chr&gt; &quot;a&quot;, &quot;rv&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;lv&quot;, &quot;rv&quot;, &quot;a&quot;, &quot;lv&quot;...
## $ weight              &lt;dbl&gt; 0.262, 0.680, 0.153, 0.243, 0.142, 0.200, 1.514...
## $ influence           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ approve             &lt;dbl&gt; 45.0, 46.0, 42.1, 45.0, 42.3, 57.0, 36.0, 46.0,...
## $ disapprove          &lt;dbl&gt; 45.0, 37.0, 45.2, 46.0, 45.8, 43.0, 44.0, 45.0,...
## $ adjusted_approve    &lt;dbl&gt; 45.7, 45.3, 43.2, 45.7, 43.4, 51.5, 37.6, 46.7,...
## $ adjusted_disapprove &lt;dbl&gt; 43.6, 38.3, 43.9, 44.6, 44.5, 44.5, 42.8, 43.6,...
## $ multiversions       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ tracking            &lt;lgl&gt; TRUE, NA, TRUE, TRUE, TRUE, TRUE, NA, TRUE, TRU...
## $ url                 &lt;chr&gt; &quot;http://www.gallup.com/poll/201617/gallup-daily...
## $ poll_id             &lt;dbl&gt; 49253, 49249, 49426, 49262, 49425, 49266, 49260...
## $ question_id         &lt;dbl&gt; 77265, 77261, 77599, 77274, 77598, 77278, 77272...
## $ createddate         &lt;chr&gt; &quot;1/23/2017&quot;, &quot;1/23/2017&quot;, &quot;3/1/2017&quot;, &quot;1/24/201...
## $ timestamp           &lt;chr&gt; &quot;00:45:20 27 Sep 2020&quot;, &quot;00:45:20 27 Sep 2020&quot;,...</code></pre>
<pre class="r"><code># Use `lubridate` to fix dates, as they are given as characters.

library(lubridate)

approval_polllist$modeldate&lt;-mdy(approval_polllist$modeldate)
approval_polllist$startdate&lt;-mdy(approval_polllist$startdate)
approval_polllist$enddate&lt;-mdy(approval_polllist$enddate)
approval_polllist$createddate&lt;-mdy(approval_polllist$createddate)</code></pre>
<div id="create-a-plot" class="section level2">
<h2>Create a plot</h2>
<pre class="r"><code>#Adding net approval
president_approval &lt;- approval_polllist %&gt;%
  mutate(net_approval = adjusted_approve - adjusted_disapprove)

#Calculating statistics
net_approval_weekly &lt;- president_approval %&gt;%
  filter(subgroup == &quot;Voters&quot;) %&gt;%
  group_by(week_number = isoweek(enddate), year=year(enddate)) %&gt;% 
  summarise(mean_app = mean(net_approval, na.rm = TRUE), sd_app = sd(net_approval, na.rm = TRUE), count_app = n(), se_app = sd_app / sqrt(count_app), t_critical = qt(0.975, count_app-1) , margin_of_error = t_critical * se_app, app_low = mean_app - margin_of_error, app_high = mean_app + margin_of_error) %&gt;%
  filter(count_app&gt;1)

#Plotting
ggplot(data = net_approval_weekly, aes(x = week_number,fill=as.factor(year))) + scale_fill_manual(values = c(&quot;red&quot;,&quot;#a1d99b&quot;,&quot;#66FFFF&quot;,&quot;#d4b9da&quot;)) + geom_line(aes(y=app_low))+geom_line(aes(y=mean_app)) + 
  geom_line(aes(y=app_high))+geom_point(aes(y=mean_app)) + facet_wrap(~year) + geom_ribbon(aes(ymin=app_low,ymax=app_high),alpha=0.3)  + geom_hline(yintercept=0, size=1.0, color=&quot;orange&quot;) + scale_y_continuous(breaks=c(-20,-17.5,-15,-12.5,-10,-7.5,-5,-2.5,0,2.5,5.0,7.5)) + scale_x_continuous(breaks=c(0, 13,26,39,52)) + labs(title=&quot;Estimating Net Approval (approve-disapprove) for Donald Trump
&quot;,subtitle=&quot;Weekly average of all polls&quot;,x=&quot;Week of the year&quot;,y=&quot;Average net approval (%)&quot;) + theme(text = element_text(size = 11),legend.position = &quot;none&quot;, panel.background = element_rect(fill = &quot;white&quot;, colour = &quot;white&quot;, size = 0.5, linetype = &quot;solid&quot;), panel.grid.major = element_line(size = 0.5, linetype = &#39;solid&#39;, colour = &quot;light grey&quot;), panel.grid.minor = element_line(size = 0.5, linetype = &#39;solid&#39;, colour = &quot; light grey&quot;))</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-2-1.png" width="648" style="display: block; margin: auto;" /></p>
<p><img src="C:/Users/CSieker/Documents/Data Analytics/website77/images/trump_approval_margin.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="compare-confidence-intervals" class="section level2">
<h2>Compare Confidence Intervals</h2>
<pre class="r"><code>#Filtering for week 15 year 2020 in the table
net_approval_week15 &lt;- net_approval_weekly %&gt;%
  filter(week_number == 15, year == 2020)

net_approval_week15</code></pre>
<pre><code>## # A tibble: 1 x 10
## # Groups:   week_number [1]
##   week_number  year mean_app sd_app count_app se_app t_critical margin_of_error
##         &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;int&gt;  &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;
## 1          15  2020    -7.29   4.15        35  0.702       2.03            1.43
## # ... with 2 more variables: app_low &lt;dbl&gt;, app_high &lt;dbl&gt;</code></pre>
<pre class="r"><code>#Filtering for week 34 year 2020 in the table
net_approval_week34 &lt;- net_approval_weekly %&gt;%
  filter(week_number == 34, year == 2020)

net_approval_week34</code></pre>
<pre><code>## # A tibble: 1 x 10
## # Groups:   week_number [1]
##   week_number  year mean_app sd_app count_app se_app t_critical margin_of_error
##         &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;int&gt;  &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;
## 1          34  2020    -11.7   5.24        32  0.927       2.04            1.89
## # ... with 2 more variables: app_low &lt;dbl&gt;, app_high &lt;dbl&gt;</code></pre>
<p>Looking at the graph, the confidence interval of the later week (week 34) is larger. There might be two reasons for this development, standard deviation and sample size. Variability might be increased and/ or the sample size might be reduced. Checking the table, we are able to identify that standard deviation indeed increased and sample size indeed decreased.</p>
</div>
</div>
<div id="gapminder-revisited" class="section level1">
<h1>Gapminder revisited</h1>
<pre class="r"><code># load gapminder HIV data
hiv &lt;- read_csv(here::here(&quot;data&quot;,&quot;adults_with_hiv_percent_age_15_49.csv&quot;))
life_expectancy &lt;- read_csv(here::here(&quot;data&quot;,&quot;life_expectancy_years.csv&quot;))

# get World bank data using wbstats
indicators &lt;- c(&quot;SP.DYN.TFRT.IN&quot;,&quot;SE.PRM.NENR&quot;, &quot;SH.DYN.MORT&quot;, &quot;NY.GDP.PCAP.KD&quot;)

library(wbstats)

worldbank_data &lt;- read_csv(here::here(&quot;data&quot;,&quot;worldbank_data.csv&quot;))

# get a dataframe of information regarding countries, indicators, sources, regions, indicator topics, lending types, income levels,  from the World Bank API 
countries &lt;-  read.csv(here::here(&quot;data&quot;,&quot;countries.csv&quot;))</code></pre>
<p>Working with the following three data frames:</p>
<ul>
<li>hiv</li>
<li>life_expectancy</li>
<li>worldbank_data</li>
</ul>
<p>As a first step, we need to tidy the data of hiv and life_expectancy.</p>
<pre class="r"><code>#glimpse(hiv)
#glimpse(life_expectancy)
#glimpse(worldbank_data)</code></pre>
<pre class="r"><code>library(countrycode)

#tidy the data fo hiv and life_expectancy
hiv_tidy &lt;- hiv %&gt;%
  pivot_longer(cols = c(&quot;1979&quot;:&quot;2011&quot;),
               names_to = &quot;date&quot; , 
               values_to = &quot;hiv_prevalence&quot;, 
               values_drop_na= FALSE)


life_expectancy_tidy &lt;- life_expectancy %&gt;%
  pivot_longer(cols = c(&quot;1800&quot;:&quot;2100&quot;),
   names_to = &quot;date&quot; , 
   values_to = &quot;life_expectancy&quot;, 
   values_drop_na= FALSE)

#Preparation for left join 
life_expectancy_tidy$date &lt;- as.double(life_expectancy_tidy$date)
hiv_tidy$date &lt;- as.double(hiv_tidy$date)

#Left join the data frames
three_combined &lt;- left_join(worldbank_data,life_expectancy_tidy) %&gt;%
  left_join(.,hiv_tidy) %&gt;%
   mutate(region= countrycode(sourcevar = country, origin = &quot;country.name&quot;,destination = &quot;region&quot;))

three_combined</code></pre>
<pre><code>## # A tibble: 12,369 x 11
##    iso2c iso3c country  date NY.GDP.PCAP.KD SE.PRM.NENR SH.DYN.MORT
##    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
##  1 AW    ABW   Aruba    1960             NA          NA          NA
##  2 AW    ABW   Aruba    1961             NA          NA          NA
##  3 AW    ABW   Aruba    1962             NA          NA          NA
##  4 AW    ABW   Aruba    1963             NA          NA          NA
##  5 AW    ABW   Aruba    1964             NA          NA          NA
##  6 AW    ABW   Aruba    1965             NA          NA          NA
##  7 AW    ABW   Aruba    1966             NA          NA          NA
##  8 AW    ABW   Aruba    1967             NA          NA          NA
##  9 AW    ABW   Aruba    1968             NA          NA          NA
## 10 AW    ABW   Aruba    1969             NA          NA          NA
## # ... with 12,359 more rows, and 4 more variables: SP.DYN.TFRT.IN &lt;dbl&gt;,
## #   life_expectancy &lt;dbl&gt;, hiv_prevalence &lt;dbl&gt;, region &lt;chr&gt;</code></pre>
<div id="relationship-between-hiv-prevalence-and-life-expectancy" class="section level2">
<h2>Relationship between HIV prevalence and life expectancy</h2>
<pre class="r"><code>#Plotting two graphs, one for all countries, one focusing on the different regions
ggplot(data = three_combined, aes(x = hiv_prevalence, y= life_expectancy )) + geom_point(alpha=0.4) + geom_smooth() + labs(title=&quot;Negative correlation between HIV prevalence and life expectancy&quot;,subtitle=&quot;HIV prevalence and life expectancy&quot;,x=&quot;HIV prevalence&quot;,y=&quot;Life expectancy&quot;) + theme_classic()</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-6-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(data = three_combined, aes(x = hiv_prevalence, y= life_expectancy )) + geom_point(alpha=0.4) + geom_smooth(method=&quot;gam&quot;) + labs(title=&quot;Negative correlation between HIV prevalence and life expectancy&quot;,subtitle=&quot;HIV prevalence and life expectancy&quot;,x=&quot;HIV prevalence&quot;,y=&quot;Life expectancy&quot;) + theme_classic() + facet_wrap(~region, scales=&quot;free&quot;)</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-6-2.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#cleaning data before calculating correlation coefficient
correlation_hiv_lifeexpectancy &lt;- three_combined %&gt;%
  filter (!is.na(hiv_prevalence &amp; life_expectancy)) %&gt;%
  select(hiv_prevalence, life_expectancy) %&gt;% 
  cor()

correlation_hiv_lifeexpectancy</code></pre>
<pre><code>##                 hiv_prevalence life_expectancy
## hiv_prevalence           1.000          -0.531
## life_expectancy         -0.531           1.000</code></pre>
<p>Overall, HIV and life expectancy are negatively correlated (p=-0.531). For regions like Sub-Saharan Africa the relationship seems rather clear, for other regions like East Asia &amp; Pacific it’s less obvious. Thus, in order to confirm a direct causal effect, a deeper investigation is necessary and also other variables should be considered.</p>
</div>
<div id="relationship-between-fertility-rate-and-gdp-per-capita" class="section level2">
<h2>Relationship between fertility rate and GDP per capita</h2>
<pre class="r"><code>#Plotting two graphs, one for all countries, one focusing on the different regions
ggplot(data = three_combined, aes(x = NY.GDP.PCAP.KD, y= SP.DYN.TFRT.IN)) + geom_point(alpha=0.4) + geom_smooth() + labs(title=&quot;Better living standard and healthcare access leads to less children&quot;,subtitle=&quot;GDP per capita and fertility rate&quot;,x=&quot;GDP per capita&quot;,y=&quot;Fertility rate&quot;) + theme_classic()</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-7-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(data = three_combined, aes(x = NY.GDP.PCAP.KD, y= SP.DYN.TFRT.IN)) + geom_point(alpha=0.4) + geom_smooth(method = lm) + labs(title=&quot;Better living standard and healthcare access leads to less children&quot;,subtitle=&quot;GDP per capita and fertility rate&quot;,x=&quot;GDP per capita&quot;,y=&quot;Fertility rate&quot;) + theme_classic() + facet_wrap(~region, scales=&quot;free&quot;)</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-7-2.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#cleaning data before calculating correlation coefficient
correlation_fertility_gdp &lt;- three_combined %&gt;%
  filter (!is.na(NY.GDP.PCAP.KD &amp; SP.DYN.TFRT.IN)) %&gt;%
  select(NY.GDP.PCAP.KD, SP.DYN.TFRT.IN) %&gt;% 
  cor()

correlation_fertility_gdp</code></pre>
<pre><code>##                NY.GDP.PCAP.KD SP.DYN.TFRT.IN
## NY.GDP.PCAP.KD          1.000         -0.509
## SP.DYN.TFRT.IN         -0.509          1.000</code></pre>
<p>Fertility rate and GDP per capita seem to be negatively correlated. Especially Sub-Saharan Africa and South Asia and Latin America &amp; Caribbean are good examples for this relationship. Higher income might lead to better access to healthcare and contraceptives. This anaylsis is underlined by a correlation coefficient of -0.509</p>
</div>
<div id="regions-having-the-most-observations-with-missing-hiv-data" class="section level2">
<h2>Regions having the most observations with missing HIV data</h2>
<pre class="r"><code>#Filtering for 1979-2011 because hiv data is only available for this time frame and then calculating both absolute and relative value of missing hiv data
hiv_miss &lt;- three_combined %&gt;%
  group_by(region) %&gt;%
  filter(date&gt;=1979) %&gt;%
  filter(date&lt;=2011)  %&gt;%
   summarize(NA_hiv = sum(is.na(hiv_prevalence)), NA_percentage = round (NA_hiv/n(), digits = 4)) %&gt;%
  arrange(desc(NA_hiv))

#Plot - absolute values
ggplot(data = hiv_miss, aes(x = reorder(region, NA_hiv), y = NA_hiv)) + geom_col() + coord_flip() + geom_text(aes(label=NA_hiv), vjust=0.5,hjust=2,angle=0, color=&quot;red&quot;, size=3) + labs(title=&quot;Missing HIV prevalence observations&quot;,subtitle=&quot;Per region / absolute values&quot;, y=&quot;Missing HIV data&quot;,x=&quot;&quot;) + theme_economist_white()</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-8-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#Plot - relative values
ggplot(data = hiv_miss, aes(x = reorder(region, NA_percentage), y = NA_percentage)) + geom_col() + coord_flip() + geom_text(aes(label=scales::percent(NA_percentage)), vjust=0.5,hjust=2,angle=0, color=&quot;red&quot;, size=3) + labs(title=&quot;Missing HIV prevalence observations&quot;,subtitle=&quot;Per region / relative values&quot;, y=&quot;Missing HIV data&quot;,x=&quot;&quot;) + theme_economist_white()</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-8-2.png" width="648" style="display: block; margin: auto;" /></p>
<p>Considering absolute values, Europe &amp; Central Asia are leading with the most missing values overall. However, considering proportion, it’s East Asia &amp; Pacific which are leading. Using the second analysis might be more helpful because not all regions do have the same number of countries.</p>
</div>
<div id="top-5-countries-with-the-greatestlowest-decrease-in-mortality-rate-per-region" class="section level2">
<h2>Top 5 countries with the greatest/lowest decrease in mortality rate per region</h2>
<pre class="r"><code>#Preparing data by filtering and untidying
improvement &lt;- three_combined %&gt;%
                select(c(&quot;country&quot;,&quot;region&quot;,&quot;date&quot;,&quot;SH.DYN.MORT&quot;)) %&gt;% 
                filter(date== &quot;1960&quot;| date==&quot;2016&quot;) %&gt;%
                pivot_wider(names_from=&quot;date&quot;, values_from=&quot;SH.DYN.MORT&quot;)

colnames(improvement) = c(&quot;country&quot;,&quot;region&quot;,&quot;start&quot;,&quot;end&quot;)

#Calculating change over the years
impro_mortality &lt;- improvement %&gt;% 
mutate(change_over_years=(end-start)/start) %&gt;% 
group_by(region) %&gt;%
summarize(country,change_over_years) %&gt;%
arrange(region,desc(change_over_years))

#top 5 per region
best_five &lt;- impro_mortality %&gt;%
            slice_min(order_by= change_over_years,n=5) %&gt;%
            summarize(country,change_over_years)

#Plotting
ggplot(best_five,aes(x=reorder(country,change_over_years),y=abs(change_over_years))) +
  geom_col(fill=&quot;dark green&quot;) + coord_flip()+ facet_wrap(~region,scales=&quot;free&quot;) + 
  labs(title=&quot;Countries with the greatest decrease in mortality 1960-2016&quot;,subtitle=&quot;Top 5 countries per region &quot;,y=&quot;Change in mortality rate between 1960 and 2016&quot;,x=&quot;&quot;) +
  geom_text(aes(label=scales::percent(change_over_years)), vjust=1,hjust=2, angle=0, color=&quot;black&quot;, size=2.5) </code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-9-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#bottom 5 per region  
worst_five &lt;- impro_mortality %&gt;%
    slice_max(order_by= change_over_years,n=5) %&gt;%
  summarize(country,change_over_years)

#Plotting
ggplot(worst_five,aes(x=reorder(country,change_over_years),y=abs(change_over_years))) +
  geom_col(fill=&quot;dark red&quot;) + coord_flip()+ facet_wrap(~region,scales=&quot;free&quot;) + 
  labs(title=&quot;Countries with the worst decrease in mortality 1960-2016&quot;,subtitle=&quot;Bottom 5 countries per region &quot;,y=&quot;Change in mortality rate between 1960 and 2016&quot;,x=&quot;&quot;) +
  geom_text(aes(label=scales::percent(change_over_years)), vjust=1,hjust=2, angle=0, color=&quot;black&quot;, size=2.5) </code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-9-2.png" width="648" style="display: block; margin: auto;" /></p>
<p>It is important to mention that the study has various limits. First, many countries do not have data for the specific time frame leading to a potential fabrication of the data. A solution might have been to use the first and last available data points of each country, however, this would have greated another issue considering the fact of comparing different times frames in that case. Further, it is potentially not enough to compare only relative values. It is not a surprise that the most developed countries had the lowest margins of improvement considering their already high level at the beginning.</p>
</div>
<div id="relationship-between-primary-school-enrollment-and-fertility-rate" class="section level2">
<h2>Relationship between primary school enrollment and fertility rate</h2>
<pre class="r"><code>#Plotting
ggplot(data = three_combined, aes(x = SE.PRM.NENR, y= SP.DYN.TFRT.IN)) + geom_point(alpha=0.4) + geom_smooth(method = lm) + labs(title=&quot;Better living standard and healthcare access leads to less children&quot;,subtitle=&quot;Primary school enrollment and fertility rate&quot;,x=&quot;Primary school enrollment&quot;,y=&quot;Fertility rate&quot;) + theme_classic() + facet_wrap(~region, scales=&quot;free&quot;)</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-10-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#cleaning data before calculating correlation coefficient
correlation_primary_fertility &lt;- three_combined %&gt;%
  filter (!is.na(SE.PRM.NENR &amp; SP.DYN.TFRT.IN)) %&gt;%
  select(SE.PRM.NENR, SP.DYN.TFRT.IN) %&gt;% 
  cor()

correlation_primary_fertility</code></pre>
<pre><code>##                SE.PRM.NENR SP.DYN.TFRT.IN
## SE.PRM.NENR          1.000         -0.716
## SP.DYN.TFRT.IN      -0.716          1.000</code></pre>
<p>Considering the correlation coefficient of -0.716, there seems to be a clear neagtive correlation between these two variables. This reflects the general opinion that besides a higher GDP especially education has a very strong impact on the fertility rate. Usually better education leads to less children in a society. This is perfectly visualized in the Sub-Saharan Africa graph or the South Asia graph.</p>
</div>
</div>
<div id="challenge-1-cdc-covid-19-public-use-data" class="section level1">
<h1>Challenge 1: CDC COVID-19 Public Use Data</h1>
<pre class="r"><code># file contains 11 variables and 3.66m rows and is well over 380Mb. 
# It will take time to download

# URL link to CDC to download data
url &lt;- &quot;https://data.cdc.gov/api/views/vbim-akqf/rows.csv?accessType=DOWNLOAD&quot;

covid_data &lt;- vroom::vroom(url)%&gt;% # If vroom::vroom(url) doesn&#39;t work, use read_csv(url)
  clean_names()</code></pre>
<div id="covid-death-by-age-group-sex-and-presence-of-co-morbidities" class="section level2">
<h2>Covid death % by age group, sex and presence of co-morbidities</h2>
<pre class="r"><code>#glimpse(covid_data)
#Data cleaning

cleaning_covid_data &lt;- covid_data %&gt;% 
  filter(medcond_yn != &quot;Missing&quot;) %&gt;% 
  filter(medcond_yn != &quot;Unknown&quot;) %&gt;% 
  filter(death_yn != &quot;Unknown&quot;) %&gt;% 
  filter(death_yn != &quot;Missing&quot;) %&gt;%
  filter(age_group != &quot;Unknown&quot;) %&gt;% 
  filter(sex != &quot;Missing&quot;) %&gt;% 
  filter(sex != &quot;Unknown&quot;) %&gt;% 
  filter(sex != &quot;Other&quot;)

#glimpse(cleaning_covid_data)

#Adding the death percentage

covid_deaths &lt;- cleaning_covid_data %&gt;% 
  group_by(age_group,sex,medcond_yn,death_yn) %&gt;% 
  count() %&gt;% 
  pivot_wider(names_from = death_yn, values_from = n) %&gt;%
  mutate(death_percentage = Yes/(Yes+No))

#glimpse(covid_deaths)</code></pre>
<pre class="r"><code>#Change label names
covid_deaths$medcond_yn_names &lt;- factor(covid_deaths$medcond_yn,
levels = c(&quot;Yes&quot;, &quot;No&quot;),
labels = c(&quot;With comorbidities&quot;, &quot;Without comorbidities&quot;))

#glimpse(covid_deaths)

#Graphical reflection
ggplot(data = covid_deaths, aes(x = age_group, y = death_percentage)) + geom_col(fill = &quot;#6b7ca4&quot;, show.legend = FALSE) +  geom_text(aes(label = round(death_percentage*100, 1), hjust = 0.6)) + labs(title = &quot;Covid death % by age group, sex and presence of co-morbidities&quot;, caption = &quot;Source:CDC&quot;) + theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank()) + scale_y_continuous(labels = scales::percent) + coord_flip() + facet_grid(medcond_yn_names ~ sex)</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-13-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="covid-death-rate-by-age-group-sex-and-whether-patient-was-admitted-to-icu" class="section level2">
<h2>Covid death rate by age group, sex and whether patient was admitted to ICU</h2>
<pre class="r"><code>#glimpse(covid_data)
#Data cleaning

cleaning_covid_icu &lt;- covid_data %&gt;% 
  filter(icu_yn != &quot;Missing&quot;) %&gt;% 
  filter(icu_yn != &quot;Unknown&quot;) %&gt;%
  filter(age_group != &quot;Unknown&quot;) %&gt;% 
  filter(sex != &quot;Missing&quot;) %&gt;% 
  filter(sex != &quot;Unknown&quot;) %&gt;% 
  filter(sex != &quot;Other&quot;) %&gt;% 
  filter(death_yn != &quot;Unknown&quot;) %&gt;% 
  filter(death_yn != &quot;Missing&quot;)

#glimpse(cleaning_covid_icu)

#Adding the death percentage

icu_covid &lt;- cleaning_covid_icu %&gt;% 
  group_by(age_group,sex,icu_yn,death_yn) %&gt;% 
  count() %&gt;% 
  pivot_wider(names_from = death_yn, values_from = n) %&gt;% 
  summarize(death_percentage = Yes/(Yes+No))

#glimpse(icu_covid)</code></pre>
<pre class="r"><code>#Change label names
icu_covid$icu_yn_names &lt;- factor(icu_covid$icu_yn,
levels = c(&quot;Yes&quot;, &quot;No&quot;),
labels = c(&quot;Admitted to ICU&quot;, &quot;No ICU&quot;))

#glimpse(icu_covid)

#Graphical reflection
ggplot(data = icu_covid, aes(x = age_group, y = death_percentage)) + geom_col(fill = &quot;#fe9481&quot;, show.legend = FALSE) + geom_text(aes(label = round(death_percentage*100, 1), hjust = 0.6)) + labs(title = &quot;Covid death % by age group, sex and whether patient was admitted to ICU&quot;, caption = &quot;Source:CDC&quot;) + theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank()) + scale_y_continuous(labels = scales::percent) + coord_flip() + facet_grid(icu_yn_names ~ sex)</code></pre>
<p><img src="blog10_files/figure-html/unnamed-chunk-15-1.png" width="648" style="display: block; margin: auto;" /></p>
<p><img src="C:/Users/CSieker/Documents/Data Analytics/website77/images/covid_death_rate_comorbidities.png" width="100%" style="display: block; margin: auto;" /><img src="C:/Users/CSieker/Documents/Data Analytics/website77/images/covid_death_rate_icu.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="challenge-2-excess-rentals-in-tfl-bike-sharing" class="section level1">
<h1>Challenge 2: Excess rentals in TfL bike sharing</h1>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx&quot;

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp &lt;- tempfile(fileext = &quot;.xlsx&quot;)))</code></pre>
<pre><code>## Response [https://airdrive-secure.s3-eu-west-1.amazonaws.com/london/dataset/number-bicycle-hires/2020-09-18T09%3A06%3A54/tfl-daily-cycle-hires.xlsx?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJJDIMAIVZJDICKHA%2F20201020%2Feu-west-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20201020T003940Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=aa5b1df3943974abb39a74d651e328da3039118cb98152de5eb3eebe4056980b&amp;X-Amz-SignedHeaders=host]
##   Date: 2020-10-20 00:39
##   Status: 200
##   Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
##   Size: 165 kB
## &lt;ON DISK&gt;  C:\Users\CSieker\AppData\Local\Temp\RtmpWEsz2s\file28d411967dd.xlsx</code></pre>
<pre class="r"><code># Use read_excel to read it as dataframe
bike0 &lt;- read_excel(bike.temp,
                   sheet = &quot;Data&quot;,
                   range = cell_cols(&quot;A:B&quot;))

# change dates to get year, month, and week
bike &lt;- bike0 %&gt;% 
  clean_names() %&gt;% 
  rename (bikes_hired = number_of_bicycle_hires) %&gt;% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))</code></pre>
<p><img src="C:/Users/CSieker/Documents/Data Analytics/website77/images/tfl_distributions_monthly.png" width="100%" style="display: block; margin: auto;" /></p>
<p><img src="C:/Users/CSieker/Documents/Data Analytics/website77/images/tfl_monthly.png" width="100%" style="display: block; margin: auto;" /></p>
<p><img src="C:/Users/CSieker/Documents/Data Analytics/website77/images/tfl_weekly.png" width="100%" style="display: block; margin: auto;" />
For both of these graphs, we will calculate the expected number of rentals per week or month between 2015-2019 and then, see how each week/month of 2020 compares to the expected rentals.</p>
<p>We need to use the mean number of bike rentals to calculated expected rentals as the mean considers all values and not only middle ones and we do not have many outliers in the sample.</p>
<div id="monthly-changes-in-bike-rentals" class="section level2">
<h2>Monthly changes in bike rentals</h2>
<pre class="r"><code>#calculate average bike hires in 2015-2019 by month (expected rentals)
expected_rentals &lt;- bike %&gt;%
  filter(year &gt;=2015 &amp; year &lt;= 2019) %&gt;%
  group_by(month) %&gt;%
  summarize(avg_hires = sum(bikes_hired)/n())

#calculate average bike hires by month including 2020 data (actual rentals)
actual_rentals &lt;- bike %&gt;%
  filter(year &gt;= 2015) %&gt;%
  group_by(year, month) %&gt;%
  summarize(actual_hires = sum(bikes_hired)/n()) %&gt;%
  inner_join(expected_rentals, by = &quot;month&quot;)

#plot the graph of change in monthly expected rentals vs actual rentals in 2015-2020
ggplot(actual_rentals, aes(x = month, y = avg_hires)) +
  geom_ribbon(aes(ymin = actual_hires, ymax = pmin(actual_hires, avg_hires), group = year,
                  alpha = 0.5),
              show.legend = FALSE,
              fill = &#39;#4CC076&#39;, color = &quot;black&quot;, size=0.15) +
  geom_ribbon(aes(ymin = avg_hires, ymax = pmin(actual_hires, avg_hires), group = year,
                  alpha = 0.5),
              show.legend = FALSE,
              fill = &quot;#CD8383&quot;, color = &quot;black&quot;, size=0.15) +
  geom_line(size = 0.5, color = &quot;blue&quot;, aes(y = avg_hires, group = 1)) +
  labs(title = &quot;Monthly changes in TfL bike rentals&quot;,
       subtitle = &quot;Change from monthly average shown in blue \n and calculated between 2015-2019&quot;,
       y = &quot;Bike rentals&quot;,x=NULL) +
  facet_wrap(~year) +
  theme(strip.background = element_rect(fill=&quot;white&quot;, size = 0.5),
              strip.text = element_text(size=7),
              panel.background = element_rect(fill = &quot;white&quot;),
              panel.grid = element_line(colour = &quot;#f0f0f0&quot;),
              plot.title = element_text(size = 7),
              axis.title.y = element_blank()) + theme(plot.title = element_text(size = 14)) </code></pre>
<p><img src="blog10_files/figure-html/first_figure-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="weekly-changes-in-bike-rentals" class="section level2">
<h2>Weekly changes in bike rentals</h2>
<pre class="r"><code>library(FreqProf)

#calculate average bike hires in 2015-2019 by week (expected rentals)
expected_rentals &lt;- bike %&gt;%
  filter(year &gt;=2015 &amp; year &lt;= 2019) %&gt;%
  group_by(week) %&gt;%
  summarize(avg_hires = sum(bikes_hired)/n())

#calculate average bike hires by week including 2020 data (actual rentals) and % change between expected and actual rentals
actual_rentals &lt;- bike %&gt;%
  filter(year &gt;= 2015) %&gt;%
  group_by(year, week) %&gt;%
  summarize(actual_hires = sum(bikes_hired)/n()) %&gt;%
  inner_join(expected_rentals, by = &quot;week&quot;) %&gt;%
  summarize(week = week, per_change = (actual_hires-avg_hires)/avg_hires)


#plot the graph of % change in weekly expected rentals vs actual rentals in 2015-2020
ggplot(actual_rentals, aes(x = week,y = per_change)) +
   annotate(&quot;rect&quot;, fill = &quot;#E0E0E0&quot;, alpha = 0.5, 
        xmin = 13, xmax = 26,
        ymin = -Inf, ymax = Inf)+  
  annotate(&quot;rect&quot;, fill = &quot;#E0E0E0&quot;, alpha = 0.5, 
        xmin = 39, xmax = 53,
        ymin = -Inf, ymax = Inf)+
   geom_ribbon(aes(ymin = pmin(0, per_change), ymax = 0, group = year,
                  alpha = 0.5),
              show.legend = FALSE,
              fill = &quot;#CD8383&quot;, color = &quot;grey&quot;) +
  geom_ribbon(aes(ymin = 0, ymax = pmax(0, per_change), group = year,
                  alpha = 0.5),
              show.legend = FALSE,
              fill = &#39;#4CC076&#39;, color = &quot;grey&quot;) +
  geom_line(size = 0.2, color = &quot;black&quot;, aes(y = per_change, group = 1)) +
  labs(title = &quot;Weekly changes in TfL bike rentals&quot;,
       subtitle = &quot;% Changes from weekly averages \n calculated between 2015-2019&quot;,
       y = &quot;Bike rentals&quot;) +
    scale_y_continuous(labels = scales::percent) +
     scale_x_continuous(breaks=c(13,26, 39, 53))+
  facet_wrap(~year) +
  theme(strip.background = element_rect(fill=&quot;white&quot;, size = 0.5),
              strip.text = element_text(size=8),
              panel.background = element_rect(fill = &quot;white&quot;),
              panel.grid = element_line(colour = &quot;#f0f0f0&quot;),
              plot.title = element_text(size = 8),
              axis.title.y = element_blank()) + theme(plot.title = element_text(size = 14))+
  geom_rug(aes(colour=ifelse(per_change&gt;=0,&quot;&gt;=0&quot;,&quot;&lt;0&quot;)),sides=&quot;b&quot;,alpha=0.5)+
    scale_colour_manual(values=c(&quot;#CD8383&quot;,&quot;#4CC076&quot;), guide=FALSE)</code></pre>
<p><img src="blog10_files/figure-html/weekly_changes-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Who did you collaborate with: Aman Sharma, Christoph Sieker, Kasia Gasiewska, Peter Moravec, Philippe Schrage, Satyam Gorry</li>
<li>Approximately how much time did you spend on this problem set: 60 hours</li>
<li>What, if anything, gave you the most trouble: Challenge 2</li>
</ul>
</div>
<div id="rubric" class="section level1">
<h1>Rubric</h1>
<p>Check minus (1/5): Displays minimal effort. Doesn’t complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn’t use plots appropriate for the variables being analyzed.</p>
<p>Check (3/5): Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output).</p>
<p><strong>Check plus (5/5): Finished all components of the assignment correctly and addressed both challenges. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you’ve written additional text to describe how you interpret the output.</strong></p>
</div>
